{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdcda462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sparsemax import Sparsemax\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, auc, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class DotProductScore(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(DotProductScore, self).__init__()\n",
    "        # 定义可学习的参数 q，使用 nn.Parameter 将其注册为模型参数\n",
    "        # q 是一个二维张量，形状为 (hidden_size, 1)，表示注意力分数的权重\n",
    "        self.q = nn.Parameter(torch.empty(size=(hidden_size, 1), dtype=torch.float32))\n",
    "        # 初始化权重\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        # 初始化权重的范围\n",
    "        initrange = 0.5\n",
    "        # 用均匀分布填充参数 q 的数据\n",
    "        self.q.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        输入：\n",
    "            - X：输入矩阵，inputs=[batch_size,seq_length,hidden_size]\n",
    "        输出：\n",
    "            - scores：输出矩阵，shape=[batch_size, seq_length]\n",
    "        \"\"\"\n",
    "        # 计算注意力分数，使用点积注意力\n",
    "        scores = torch.matmul(inputs, self.q)\n",
    "        \n",
    "        # 压缩张量的最后一个维度，将其从 (batch_size, seq_length, 1) 变为 (batch_size, seq_length)\n",
    "        scores = scores.squeeze(-1)\n",
    "        \n",
    "        return scores\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.scores = DotProductScore(hidden_size)\n",
    "        self.sparsemax = Sparsemax(dim=1)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        scores = self.scores(X)\n",
    "        arrange = torch.arange(X.size(1), dtype=torch.float32, device=X.device).unsqueeze(0)\n",
    "        mask = (arrange < valid_lens.unsqueeze(-1)).float()\n",
    "        scores = scores * mask - (1 - mask) * 1e9\n",
    "        attention_weights = nn.functional.softmax(scores, dim=-1)  # 保留 Softmax 用于计算注意力权重\n",
    "        attention_weights = self.sparsemax(attention_weights)\n",
    "        out = torch.matmul(attention_weights.unsqueeze(1), X).squeeze(1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ModelLSTMAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout, ins_num):\n",
    "        super(ModelLSTMAttention, self).__init__()\n",
    "        self.ins_num = ins_num\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        \n",
    "        self.attention = Attention(hidden_size * 2)\n",
    "        \n",
    "        # 添加 Batch Normalization 层\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size * 2)  # 使用 hidden_size * 2，根据你的模型要求进行调整\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc_1 = nn.Linear(self.ins_num, 1)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, seq, valid_lens):\n",
    "        \n",
    "        output, _ = self.lstm(seq)\n",
    "        valid_lens = valid_lens.view(-1,).to(device)\n",
    "        out = self.attention(output, valid_lens)\n",
    "       \n",
    "        # 应用 Batch Normalization\n",
    "        out = self.bn1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out.reshape(-1, self.ins_num)\n",
    "        out = self.fc_1(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# 读取 TSV 文件并提取指定列的信息\n",
    "def read_tsv(filename, inf_ind, skip_1st=False, file_encoding=\"utf8\"):\n",
    "    extract_inf = []\n",
    "    with open(filename, \"r\", encoding=file_encoding) as tsv_f:\n",
    "        if skip_1st:\n",
    "            tsv_f.readline()\n",
    "        line = tsv_f.readline()\n",
    "        while line:\n",
    "            line_list = line.strip().split(\"\\t\")\n",
    "            temp_inf = [line_list[ind] for ind in inf_ind]\n",
    "            extract_inf.append(temp_inf)\n",
    "            line = tsv_f.readline()\n",
    "    return extract_inf\n",
    "\n",
    "# 读取氨基酸特征文件并生成特征字典\n",
    "def get_features(filename, f_num=15):\n",
    "    f_list = read_tsv(filename, list(range(16)), True)\n",
    "    f_dict = {}\n",
    "    left_num = 0\n",
    "    right_num = 0\n",
    "    if f_num > 15:\n",
    "        left_num = (f_num - 15) // 2\n",
    "        right_num = f_num - 15 - left_num\n",
    "    for f in f_list:\n",
    "        f_dict[f[0]] = [0] * left_num + [float(x) for x in f[1:]] + [0] * right_num\n",
    "    f_dict[\"X\"] = [0] * f_num\n",
    "    return f_dict\n",
    "\n",
    "def generate_input(sps, sp_lbs, feature_dict, feature_num, ins_num, max_len):\n",
    "    # 用于存储输入数据、标签和序列长度的列表\n",
    "    xs, ys, lens = [], [], []\n",
    "\n",
    "    # 遍历每个样本（sp表示样本）\n",
    "    for i, sp in enumerate(sps):\n",
    "        # 添加样本的标签\n",
    "        ys.append(sp_lbs[i])\n",
    "\n",
    "        # 将每条序列的原始长度添加到列表中，空序列用0填充\n",
    "        lens.extend([len(tcr[0]) if tcr[0] else 0 for tcr in sp])\n",
    "\n",
    "    # 确保序列数量为 ins_num\n",
    "    while len(lens) % ins_num != 0:\n",
    "        lens = np.concatenate((lens, np.array([0])))  # 添加一个空序列\n",
    "\n",
    "    # 将 lens 转换为 NumPy 数组，为了后续的维度调整\n",
    "    lens = np.array(lens)\n",
    "\n",
    "    # 将 lens 调整为正确的形状\n",
    "    lens = lens.reshape(-1, ins_num)\n",
    "\n",
    "    # 检查是否有缺失的样本，如果有则进行填充\n",
    "    while lens.shape[0] < len(sps):\n",
    "        lens = np.concatenate((lens, np.zeros((1, ins_num))), axis=0)\n",
    "\n",
    "    # 遍历每个样本（sp表示样本）\n",
    "    for i, sp in enumerate(sps):\n",
    "        # 初始化一个3D张量，用于存储特征矩阵，初始值全为0\n",
    "        # 使用列表推导式来确保为每个样本创建一个新的列表\n",
    "        x = [[[0] * feature_num for _ in range(max_len)] for _ in range(ins_num)]\n",
    "\n",
    "        # 遍历样本中的每条序列（tcr表示T细胞受体序列）\n",
    "        seq_count = 0  # 用于计数实际插入的序列数量\n",
    "        for j, tcr in enumerate(sp):\n",
    "            # 获取序列的氨基酸序列\n",
    "            tcr_seq = tcr[0]\n",
    "            # 计算需要填充的右侧数量，以便使序列达到指定的最大长度\n",
    "            right_num = max_len - len(tcr_seq)\n",
    "\n",
    "            # 在氨基酸序列右侧填充'X'，使其达到最大长度\n",
    "            tcr_seq += \"X\" * right_num\n",
    "\n",
    "            # 用于存储氨基酸特征矩阵\n",
    "            tcr_matrix = []\n",
    "\n",
    "            # 遍历氨基酸序列中的每个氨基酸，将其特征添加到矩阵中\n",
    "            for aa in tcr_seq:\n",
    "                tcr_matrix.append(feature_dict[aa.upper()])\n",
    "\n",
    "            # 将填充后的特征矩阵放入3D张量中的相应位置\n",
    "            x[seq_count] = tcr_matrix\n",
    "            seq_count += 1\n",
    "\n",
    "        xs.append(x)\n",
    "\n",
    "    # 将列表转换为NumPy数组\n",
    "    xs = np.array(xs)\n",
    "\n",
    "    # 转换为PyTorch张量，指定数据类型为float32\n",
    "    xs = torch.tensor(xs, dtype=torch.float32)\n",
    "\n",
    "    # 交换张量的维度，将最后两个维度互换\n",
    "    xs = xs.swapaxes(2, 3)\n",
    "\n",
    "    # 将样本标签转换为NumPy数组\n",
    "    ys = np.array(ys)\n",
    "\n",
    "    # 将标签转换为PyTorch张量，指定数据类型为float32，并调整维度\n",
    "    ys = torch.tensor(ys, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    # 将序列长度转换为PyTorch张量\n",
    "    lens = torch.tensor(lens, dtype=torch.long)\n",
    "\n",
    "    # 返回生成的输入数据、标签和序列长度\n",
    "\n",
    "    return xs, ys, lens\n",
    "\n",
    "def load_data(sample_dir):\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    for sample_file in os.listdir(sample_dir):\n",
    "        # 读取样本数据\n",
    "        training_data.append(read_tsv(os.path.join(sample_dir, sample_file), [0, 1], True))\n",
    "        # 获取样本标签\n",
    "        if \"P\" in sample_file:\n",
    "            training_labels.append(1)\n",
    "        elif \"H\" in sample_file:\n",
    "            training_labels.append(0)\n",
    "        else:\n",
    "            print(\"Wrong sample filename! Please name positive samples with 'P' and negative samples with 'H'.\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "    return training_data, training_labels\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "def evaluate(model, criterion, test_loader, device='cpu'):\n",
    "    test_total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_batch_x, test_batch_y, test_valid_lens in test_loader:\n",
    "            test_batch_x = test_batch_x.view(-1, 24, 15).to(device)\n",
    "            test_batch_y = test_batch_y.to(device)\n",
    "            test_pred = model(test_batch_x, test_valid_lens)\n",
    "\n",
    "            test_loss = criterion(test_pred, test_batch_y)\n",
    "            test_total_loss += test_loss.item()\n",
    "            all_preds.append(test_pred.cpu().numpy())\n",
    "            all_labels.append(test_batch_y.cpu().numpy())\n",
    "            \n",
    "        test_avg_loss = test_total_loss / len(test_loader)\n",
    "        return test_avg_loss, all_preds, all_labels\n",
    "\n",
    "def train(fold, model, criterion, optimizer, train_loader, test_loader, epoches=100, device='cpu'):\n",
    "    \n",
    "    model_path = f'../model(LSTMY)/{disease_name}checkpoint{fold}.pt'  # 修改模型文件的保存路径和命名\n",
    "    early_stopping = EarlyStopping(PATIENCE, path=model_path, verbose=False)\n",
    "    \n",
    "    # 存储训练和测试损失\n",
    "    epoch_train_losses = []\n",
    "    epoch_test_losses = []\n",
    "    with tqdm(total=epoches) as t:\n",
    "        t.set_description(f'{disease_name} - Fold {fold}')  # 添加疾病名称\n",
    "        for epoch in range(epoches):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for batch_x, batch_y, valid_lens in train_loader:\n",
    "                batch_x = batch_x.view(-1, 24, 15).to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                pred = model(batch_x, valid_lens)\n",
    "\n",
    "                loss = criterion(pred, batch_y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            # 记录训练损失\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            epoch_train_losses.append(avg_loss)\n",
    "            # 记录评估损失\n",
    "            test_avg_loss, _, _ = evaluate(model, criterion, test_loader, device=device)\n",
    "            epoch_test_losses.append(test_avg_loss)\n",
    "            \n",
    "            t.set_postfix(loss=avg_loss, test_loss=test_avg_loss)\n",
    "            t.update(1)\n",
    "            \n",
    "            # 向EarlyStopping类别添加新轮次的损失\n",
    "            early_stopping(test_avg_loss, model)\n",
    "            # 判别是否满足提前退出的条件\n",
    "            if early_stopping.early_stop:\n",
    "                # 恢复训练中的最优模型\n",
    "                model.load_state_dict(torch.load(model_path))\n",
    "                #print('Early stopping')\n",
    "                break\n",
    "def metrics(all_preds, all_labels, threshold=0.5):\n",
    "    # 计算二进制分类指标\n",
    "    binary_preds = (all_preds > threshold).astype(int)\n",
    "    conf_matrix = confusion_matrix(all_labels, binary_preds)\n",
    "    accuracy = accuracy_score(all_labels, binary_preds)\n",
    "    sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "    \n",
    "    return accuracy, sensitivity, specificity, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c8d0773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on RA dataset: 322 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RA - Fold 0:  61%|▌| 1214/2000 [01:05<00:42, 18.67it/s, loss=0.441, test_loss=0.\n",
      "RA - Fold 1:  59%|▌| 1183/2000 [01:47<01:14, 11.03it/s, loss=0.426, test_loss=0.\n",
      "RA - Fold 2:  32%|▎| 632/2000 [00:58<02:05, 10.86it/s, loss=0.439, test_loss=0.7\n",
      "RA - Fold 3:  62%|▌| 1240/2000 [01:54<01:09, 10.87it/s, loss=0.363, test_loss=0.\n",
      "RA - Fold 4:  58%|▌| 1152/2000 [01:46<01:18, 10.77it/s, loss=0.432, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.7671\n",
      "Mean Sensitivity (RA): 0.3889\n",
      "Mean Specificity (RA): 0.9579\n",
      "Mean AUC (RA): 0.8372\n",
      "Working on T1D dataset: 411 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1D - Fold 0:  79%|▊| 1583/2000 [03:11<00:50,  8.27it/s, loss=0.404, test_loss=0\n",
      "T1D - Fold 1:  70%|▋| 1410/2000 [02:54<01:12,  8.10it/s, loss=0.484, test_loss=0\n",
      "T1D - Fold 2:  61%|▌| 1224/2000 [02:36<01:39,  7.82it/s, loss=0.434, test_loss=0\n",
      "T1D - Fold 3:  73%|▋| 1454/2000 [03:03<01:09,  7.91it/s, loss=0.435, test_loss=0\n",
      "T1D - Fold 4:  41%|▍| 822/2000 [01:45<02:30,  7.82it/s, loss=0.415, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9465\n",
      "Mean Sensitivity (T1D): 0.9036\n",
      "Mean Specificity (T1D): 0.9860\n",
      "Mean AUC (T1D): 0.9898\n",
      "Working on MS dataset: 508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS - Fold 0:  71%|▋| 1412/2000 [03:25<01:25,  6.88it/s, loss=0.416, test_loss=0.\n",
      "MS - Fold 1:  57%|▌| 1133/2000 [02:42<02:04,  6.96it/s, loss=0.461, test_loss=0.\n",
      "MS - Fold 2:  71%|▋| 1418/2000 [03:25<01:24,  6.89it/s, loss=0.442, test_loss=0.\n",
      "MS - Fold 3:  78%|▊| 1550/2000 [03:47<01:05,  6.83it/s, loss=0.462, test_loss=0.\n",
      "MS - Fold 4:  73%|▋| 1457/2000 [03:35<01:20,  6.78it/s, loss=0.436, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9803\n",
      "Mean Sensitivity (MS): 0.9660\n",
      "Mean Specificity (MS): 1.0000\n",
      "Mean AUC (MS): 0.9948\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IAA - Fold 0:  84%|▊| 1682/2000 [02:12<00:25, 12.70it/s, loss=0.427, test_loss=0\n",
      "IAA - Fold 1:  83%|▊| 1658/2000 [02:10<00:26, 12.75it/s, loss=0.432, test_loss=0\n",
      "IAA - Fold 2:  67%|▋| 1346/2000 [01:45<00:51, 12.73it/s, loss=0.41, test_loss=0.\n",
      "IAA - Fold 3:  72%|▋| 1432/2000 [01:51<00:44, 12.80it/s, loss=0.441, test_loss=0\n",
      "IAA - Fold 4:  91%|▉| 1825/2000 [02:16<00:13, 13.36it/s, loss=0.439, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9247\n",
      "Mean Sensitivity (IAA): 0.7077\n",
      "Mean Specificity (IAA): 0.9907\n",
      "Mean AUC (IAA): 0.9607\n",
      "Working on RA dataset: 322 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RA - Fold 0:  53%|▌| 1068/2000 [01:35<01:22, 11.24it/s, loss=0.451, test_loss=0.\n",
      "RA - Fold 1:  74%|▋| 1485/2000 [02:14<00:46, 11.01it/s, loss=0.476, test_loss=0.\n",
      "RA - Fold 2:  68%|▋| 1362/2000 [02:04<00:58, 10.98it/s, loss=0.372, test_loss=0.\n",
      "RA - Fold 3:  32%|▎| 641/2000 [00:57<02:00, 11.24it/s, loss=0.411, test_loss=0.7\n",
      "RA - Fold 4:  62%|▌| 1245/2000 [01:54<01:09, 10.87it/s, loss=0.432, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.7795\n",
      "Mean Sensitivity (RA): 0.4630\n",
      "Mean Specificity (RA): 0.9393\n",
      "Mean AUC (RA): 0.8585\n",
      "Working on T1D dataset: 411 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1D - Fold 0:  64%|▋| 1280/2000 [02:34<01:26,  8.29it/s, loss=0.472, test_loss=0\n",
      "T1D - Fold 1:  68%|▋| 1354/2000 [02:44<01:18,  8.24it/s, loss=0.406, test_loss=0\n",
      "T1D - Fold 2:  60%|▌| 1210/2000 [02:34<01:40,  7.84it/s, loss=0.473, test_loss=0\n",
      "T1D - Fold 3:  73%|▋| 1464/2000 [03:03<01:07,  7.97it/s, loss=0.411, test_loss=0\n",
      "T1D - Fold 4:  43%|▍| 860/2000 [01:49<02:24,  7.87it/s, loss=0.448, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9392\n",
      "Mean Sensitivity (T1D): 0.9036\n",
      "Mean Specificity (T1D): 0.9720\n",
      "Mean AUC (T1D): 0.9811\n",
      "Working on MS dataset: 508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS - Fold 0:  82%|▊| 1630/2000 [03:57<00:53,  6.86it/s, loss=0.449, test_loss=0.\n",
      "MS - Fold 1:  87%|▊| 1737/2000 [04:10<00:37,  6.93it/s, loss=0.403, test_loss=0.\n",
      "MS - Fold 2:  74%|▋| 1486/2000 [03:38<01:15,  6.80it/s, loss=0.427, test_loss=0.\n",
      "MS - Fold 3:  61%|▌| 1223/2000 [03:00<01:54,  6.77it/s, loss=0.415, test_loss=0.\n",
      "MS - Fold 4:  50%|▌| 1005/2000 [02:27<02:26,  6.80it/s, loss=0.464, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9724\n",
      "Mean Sensitivity (MS): 0.9626\n",
      "Mean Specificity (MS): 0.9860\n",
      "Mean AUC (MS): 0.9909\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IAA - Fold 0:  89%|▉| 1780/2000 [02:19<00:17, 12.72it/s, loss=0.388, test_loss=0\n",
      "IAA - Fold 1:  80%|▊| 1605/2000 [02:05<00:30, 12.80it/s, loss=0.464, test_loss=0\n",
      "IAA - Fold 2:  58%|▌| 1168/2000 [01:30<01:04, 12.86it/s, loss=0.419, test_loss=0\n",
      "IAA - Fold 3:  82%|▊| 1633/2000 [02:07<00:28, 12.80it/s, loss=0.451, test_loss=0\n",
      "IAA - Fold 4:  74%|▋| 1490/2000 [01:57<00:40, 12.64it/s, loss=0.356, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9247\n",
      "Mean Sensitivity (IAA): 0.7231\n",
      "Mean Specificity (IAA): 0.9860\n",
      "Mean AUC (IAA): 0.9405\n",
      "Working on RA dataset: 322 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RA - Fold 0:  71%|▋| 1426/2000 [02:14<00:54, 10.62it/s, loss=0.492, test_loss=0.\n",
      "RA - Fold 1:  41%|▍| 813/2000 [01:11<01:44, 11.33it/s, loss=0.489, test_loss=0.4\n",
      "RA - Fold 2:  74%|▋| 1471/2000 [02:10<00:46, 11.28it/s, loss=0.377, test_loss=0.\n",
      "RA - Fold 3:  40%|▍| 806/2000 [01:12<01:47, 11.13it/s, loss=0.461, test_loss=0.6\n",
      "RA - Fold 4:  63%|▋| 1267/2000 [01:54<01:06, 11.03it/s, loss=0.437, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.7764\n",
      "Mean Sensitivity (RA): 0.4259\n",
      "Mean Specificity (RA): 0.9533\n",
      "Mean AUC (RA): 0.8601\n",
      "Working on T1D dataset: 411 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1D - Fold 0:  62%|▌| 1244/2000 [02:31<01:31,  8.24it/s, loss=0.422, test_loss=0\n",
      "T1D - Fold 1:  39%|▍| 788/2000 [01:36<02:27,  8.20it/s, loss=0.418, test_loss=0.\n",
      "T1D - Fold 2:  51%|▌| 1017/2000 [02:03<01:58,  8.26it/s, loss=0.461, test_loss=0\n",
      "T1D - Fold 3:  55%|▌| 1094/2000 [02:14<01:51,  8.12it/s, loss=0.441, test_loss=0\n",
      "T1D - Fold 4:  43%|▍| 862/2000 [01:48<02:23,  7.91it/s, loss=0.457, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9148\n",
      "Mean Sensitivity (T1D): 0.8528\n",
      "Mean Specificity (T1D): 0.9720\n",
      "Mean AUC (T1D): 0.9782\n",
      "Working on MS dataset: 508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS - Fold 0:  75%|▋| 1496/2000 [03:47<01:16,  6.57it/s, loss=0.456, test_loss=0.\n",
      "MS - Fold 1:  56%|▌| 1116/2000 [02:49<02:14,  6.57it/s, loss=0.392, test_loss=0.\n",
      "MS - Fold 2:  51%|▌| 1022/2000 [02:35<02:28,  6.56it/s, loss=0.371, test_loss=0.\n",
      "MS - Fold 3:  82%|▊| 1648/2000 [04:04<00:52,  6.73it/s, loss=0.406, test_loss=0.\n",
      "MS - Fold 4:  54%|▌| 1073/2000 [02:36<02:14,  6.87it/s, loss=0.438, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9547\n",
      "Mean Sensitivity (MS): 0.9524\n",
      "Mean Specificity (MS): 0.9579\n",
      "Mean AUC (MS): 0.9871\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IAA - Fold 0:  84%|▊| 1679/2000 [02:07<00:24, 13.15it/s, loss=0.448, test_loss=0\n",
      "IAA - Fold 1: 100%|█| 2000/2000 [02:32<00:00, 13.10it/s, loss=0.382, test_loss=0\n",
      "IAA - Fold 2:  96%|▉| 1916/2000 [02:31<00:06, 12.65it/s, loss=0.389, test_loss=0\n",
      "IAA - Fold 3:  86%|▊| 1711/2000 [02:14<00:22, 12.75it/s, loss=0.4, test_loss=0.1\n",
      "IAA - Fold 4: 100%|█| 2000/2000 [02:37<00:00, 12.68it/s, loss=0.414, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.8961\n",
      "Mean Sensitivity (IAA): 0.6000\n",
      "Mean Specificity (IAA): 0.9860\n",
      "Mean AUC (IAA): 0.9186\n",
      "Working on RA dataset: 322 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RA - Fold 0:  48%|▍| 967/2000 [01:32<01:38, 10.47it/s, loss=0.419, test_loss=0.5\n",
      "RA - Fold 1:  63%|▋| 1259/2000 [02:00<01:10, 10.45it/s, loss=0.402, test_loss=0.\n",
      "RA - Fold 2:  82%|▊| 1633/2000 [02:36<00:35, 10.41it/s, loss=0.478, test_loss=0.\n",
      "RA - Fold 3:  66%|▋| 1324/2000 [02:07<01:04, 10.42it/s, loss=0.478, test_loss=0.\n",
      "RA - Fold 4:  88%|▉| 1763/2000 [02:39<00:21, 11.03it/s, loss=0.435, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.8261\n",
      "Mean Sensitivity (RA): 0.5741\n",
      "Mean Specificity (RA): 0.9533\n",
      "Mean AUC (RA): 0.9020\n",
      "Working on T1D dataset: 411 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1D - Fold 0:  79%|▊| 1572/2000 [03:07<00:50,  8.39it/s, loss=0.469, test_loss=0\n",
      "T1D - Fold 1:  60%|▌| 1209/2000 [02:27<01:36,  8.20it/s, loss=0.427, test_loss=0\n",
      "T1D - Fold 2: 100%|█| 2000/2000 [04:04<00:00,  8.19it/s, loss=0.539, test_loss=0\n",
      "T1D - Fold 3:  50%|▍| 990/2000 [02:01<02:03,  8.17it/s, loss=0.456, test_loss=0.\n",
      "T1D - Fold 4:  49%|▍| 972/2000 [01:57<02:04,  8.27it/s, loss=0.397, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9343\n",
      "Mean Sensitivity (T1D): 0.8782\n",
      "Mean Specificity (T1D): 0.9860\n",
      "Mean AUC (T1D): 0.9856\n",
      "Working on MS dataset: 508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS - Fold 0:  63%|▋| 1269/2000 [03:12<01:51,  6.58it/s, loss=0.428, test_loss=0.\n",
      "MS - Fold 1:  70%|▋| 1397/2000 [03:36<01:33,  6.44it/s, loss=0.413, test_loss=0.\n",
      "MS - Fold 2:  55%|▌| 1100/2000 [02:49<02:19,  6.47it/s, loss=0.437, test_loss=0.\n",
      "MS - Fold 3:  62%|▌| 1237/2000 [03:09<01:57,  6.51it/s, loss=0.45, test_loss=0.2\n",
      "MS - Fold 4:  71%|▋| 1419/2000 [03:27<01:24,  6.84it/s, loss=0.431, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9803\n",
      "Mean Sensitivity (MS): 0.9694\n",
      "Mean Specificity (MS): 0.9953\n",
      "Mean AUC (MS): 0.9971\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IAA - Fold 0:  89%|▉| 1781/2000 [02:14<00:16, 13.29it/s, loss=0.423, test_loss=0\n",
      "IAA - Fold 1:  80%|▊| 1595/2000 [02:01<00:30, 13.12it/s, loss=0.437, test_loss=0\n",
      "IAA - Fold 2:  78%|▊| 1551/2000 [02:00<00:34, 12.87it/s, loss=0.386, test_loss=0\n",
      "IAA - Fold 3:  81%|▊| 1629/2000 [02:07<00:29, 12.74it/s, loss=0.396, test_loss=0\n",
      "IAA - Fold 4:  56%|▌| 1129/2000 [01:29<01:08, 12.64it/s, loss=0.421, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9104\n",
      "Mean Sensitivity (IAA): 0.6462\n",
      "Mean Specificity (IAA): 0.9907\n",
      "Mean AUC (IAA): 0.9642\n",
      "Working on RA dataset: 322 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RA - Fold 0:  53%|▌| 1067/2000 [01:38<01:26, 10.82it/s, loss=0.446, test_loss=0.\n",
      "RA - Fold 1:  35%|▎| 695/2000 [01:05<02:02, 10.63it/s, loss=0.465, test_loss=0.6\n",
      "RA - Fold 2:  57%|▌| 1147/2000 [01:49<01:21, 10.50it/s, loss=0.432, test_loss=0.\n",
      "RA - Fold 3:  62%|▌| 1240/2000 [01:57<01:11, 10.59it/s, loss=0.412, test_loss=0.\n",
      "RA - Fold 4:  71%|▋| 1412/2000 [02:14<00:56, 10.50it/s, loss=0.387, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.7826\n",
      "Mean Sensitivity (RA): 0.4074\n",
      "Mean Specificity (RA): 0.9720\n",
      "Mean AUC (RA): 0.8710\n",
      "Working on T1D dataset: 411 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1D - Fold 0:  58%|▌| 1163/2000 [02:28<01:46,  7.84it/s, loss=0.482, test_loss=0\n",
      "T1D - Fold 1:  38%|▍| 763/2000 [01:38<02:39,  7.75it/s, loss=0.447, test_loss=0.\n",
      "T1D - Fold 2:  56%|▌| 1122/2000 [02:16<01:46,  8.21it/s, loss=0.427, test_loss=0\n",
      "T1D - Fold 3:  62%|▌| 1240/2000 [02:28<01:31,  8.34it/s, loss=0.446, test_loss=0\n",
      "T1D - Fold 4:  48%|▍| 954/2000 [01:54<02:05,  8.35it/s, loss=0.445, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9246\n",
      "Mean Sensitivity (T1D): 0.8832\n",
      "Mean Specificity (T1D): 0.9626\n",
      "Mean AUC (T1D): 0.9783\n",
      "Working on MS dataset: 508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS - Fold 0:  91%|▉| 1825/2000 [04:30<00:25,  6.75it/s, loss=0.64, test_loss=0.1\n",
      "MS - Fold 1:  72%|▋| 1444/2000 [03:34<01:22,  6.75it/s, loss=0.47, test_loss=0.1\n",
      "MS - Fold 2:  55%|▌| 1104/2000 [02:47<02:16,  6.59it/s, loss=0.442, test_loss=0.\n",
      "MS - Fold 3:  63%|▋| 1261/2000 [03:16<01:55,  6.41it/s, loss=0.438, test_loss=0.\n",
      "MS - Fold 4:  86%|▊| 1714/2000 [04:25<00:44,  6.47it/s, loss=0.434, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9744\n",
      "Mean Sensitivity (MS): 0.9762\n",
      "Mean Specificity (MS): 0.9720\n",
      "Mean AUC (MS): 0.9917\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IAA - Fold 0:  72%|▋| 1445/2000 [01:53<00:43, 12.75it/s, loss=0.438, test_loss=0\n",
      "IAA - Fold 1:  81%|▊| 1627/2000 [02:02<00:28, 13.28it/s, loss=0.444, test_loss=0\n",
      "IAA - Fold 2: 100%|█| 2000/2000 [02:30<00:00, 13.31it/s, loss=0.444, test_loss=0\n",
      "IAA - Fold 3: 100%|█| 2000/2000 [02:31<00:00, 13.23it/s, loss=0.384, test_loss=0\n",
      "IAA - Fold 4:  56%|▌| 1116/2000 [01:25<01:07, 13.04it/s, loss=0.418, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9319\n",
      "Mean Sensitivity (IAA): 0.7692\n",
      "Mean Specificity (IAA): 0.9813\n",
      "Mean AUC (IAA): 0.9688\n",
      "Working on RA dataset: 322 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RA - Fold 0:  51%|▌| 1027/2000 [01:35<01:30, 10.74it/s, loss=0.442, test_loss=0.\n",
      "RA - Fold 1:  56%|▌| 1118/2000 [01:44<01:22, 10.69it/s, loss=0.421, test_loss=0.\n",
      "RA - Fold 2:  71%|▋| 1419/2000 [02:09<00:53, 10.92it/s, loss=0.444, test_loss=0.\n",
      "RA - Fold 3:  58%|▌| 1168/2000 [01:48<01:17, 10.76it/s, loss=0.397, test_loss=0.\n",
      "RA - Fold 4:  54%|▌| 1077/2000 [01:43<01:28, 10.38it/s, loss=0.434, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.7795\n",
      "Mean Sensitivity (RA): 0.4907\n",
      "Mean Specificity (RA): 0.9252\n",
      "Mean AUC (RA): 0.8825\n",
      "Working on T1D dataset: 411 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1D - Fold 0:  67%|▋| 1331/2000 [02:49<01:25,  7.85it/s, loss=0.449, test_loss=0\n",
      "T1D - Fold 1:  38%|▍| 753/2000 [01:37<02:40,  7.76it/s, loss=0.472, test_loss=0.\n",
      "T1D - Fold 2:  53%|▌| 1058/2000 [02:13<01:58,  7.92it/s, loss=0.458, test_loss=0\n",
      "T1D - Fold 3:  61%|▌| 1226/2000 [02:37<01:39,  7.77it/s, loss=0.469, test_loss=0\n",
      "T1D - Fold 4:  52%|▌| 1040/2000 [02:06<01:57,  8.20it/s, loss=0.424, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9197\n",
      "Mean Sensitivity (T1D): 0.8528\n",
      "Mean Specificity (T1D): 0.9813\n",
      "Mean AUC (T1D): 0.9881\n",
      "Working on MS dataset: 508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS - Fold 0:  43%|▍| 852/2000 [02:04<02:47,  6.84it/s, loss=0.418, test_loss=0.2\n",
      "MS - Fold 1:  89%|▉| 1782/2000 [02:29<00:18, 11.92it/s, loss=0.362, test_loss=0.\n",
      "MS - Fold 2:  79%|▊| 1589/2000 [01:45<00:27, 15.05it/s, loss=0.431, test_loss=0.\n",
      "MS - Fold 3:  81%|▊| 1623/2000 [01:46<00:24, 15.21it/s, loss=0.464, test_loss=0.\n",
      "MS - Fold 4:  91%|▉| 1824/2000 [01:59<00:11, 15.32it/s, loss=0.392, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9705\n",
      "Mean Sensitivity (MS): 0.9592\n",
      "Mean Specificity (MS): 0.9860\n",
      "Mean AUC (MS): 0.9936\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IAA - Fold 0:  60%|▌| 1199/2000 [00:42<00:28, 28.43it/s, loss=0.47, test_loss=0.\n",
      "IAA - Fold 1:  76%|▊| 1529/2000 [00:54<00:16, 27.99it/s, loss=0.472, test_loss=0\n",
      "IAA - Fold 2:  75%|▊| 1507/2000 [00:53<00:17, 27.99it/s, loss=0.448, test_loss=0\n",
      "IAA - Fold 3:  87%|▊| 1731/2000 [01:02<00:09, 27.91it/s, loss=0.41, test_loss=0.\n",
      "IAA - Fold 4:  88%|▉| 1759/2000 [01:03<00:08, 27.52it/s, loss=0.381, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9140\n",
      "Mean Sensitivity (IAA): 0.6769\n",
      "Mean Specificity (IAA): 0.9860\n",
      "Mean AUC (IAA): 0.9566\n",
      "Working on RA dataset: 322 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RA - Fold 0:  38%|▍| 755/2000 [00:32<00:52, 23.54it/s, loss=0.458, test_loss=0.6\n",
      "RA - Fold 1:  52%|▌| 1049/2000 [00:43<00:39, 24.21it/s, loss=0.455, test_loss=0.\n",
      "RA - Fold 2:  49%|▍| 986/2000 [00:40<00:41, 24.30it/s, loss=0.384, test_loss=0.4\n",
      "RA - Fold 3:  41%|▍| 823/2000 [00:34<00:49, 23.88it/s, loss=0.447, test_loss=0.6\n",
      "RA - Fold 4:  53%|▌| 1068/2000 [00:44<00:38, 24.17it/s, loss=0.478, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.7950\n",
      "Mean Sensitivity (RA): 0.4722\n",
      "Mean Specificity (RA): 0.9579\n",
      "Mean AUC (RA): 0.8986\n",
      "Working on T1D dataset: 411 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1D - Fold 0:  64%|▋| 1274/2000 [01:07<00:38, 18.80it/s, loss=0.438, test_loss=0\n",
      "T1D - Fold 1:  40%|▍| 790/2000 [00:42<01:05, 18.59it/s, loss=0.441, test_loss=0.\n",
      "T1D - Fold 2:  43%|▍| 867/2000 [00:46<01:00, 18.78it/s, loss=0.458, test_loss=0.\n",
      "T1D - Fold 3:  74%|▋| 1477/2000 [01:20<00:28, 18.29it/s, loss=0.456, test_loss=0\n",
      "T1D - Fold 4:  61%|▌| 1216/2000 [01:05<00:42, 18.57it/s, loss=0.469, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9148\n",
      "Mean Sensitivity (T1D): 0.8629\n",
      "Mean Specificity (T1D): 0.9626\n",
      "Mean AUC (T1D): 0.9784\n",
      "Working on MS dataset: 508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS - Fold 0:  66%|▋| 1319/2000 [01:26<00:44, 15.24it/s, loss=0.341, test_loss=0.\n",
      "MS - Fold 1:  86%|▊| 1726/2000 [01:54<00:18, 15.02it/s, loss=0.405, test_loss=0.\n",
      "MS - Fold 2:  70%|▋| 1405/2000 [01:33<00:39, 15.09it/s, loss=0.415, test_loss=0.\n",
      "MS - Fold 3:  51%|▌| 1016/2000 [01:08<01:06, 14.84it/s, loss=0.386, test_loss=0.\n",
      "MS - Fold 4:  48%|▍| 960/2000 [01:04<01:09, 14.91it/s, loss=0.458, test_loss=0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9744\n",
      "Mean Sensitivity (MS): 0.9626\n",
      "Mean Specificity (MS): 0.9907\n",
      "Mean AUC (MS): 0.9941\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IAA - Fold 0:  57%|▌| 1140/2000 [00:40<00:30, 27.90it/s, loss=0.432, test_loss=0\n",
      "IAA - Fold 1:  74%|▋| 1477/2000 [00:53<00:18, 27.81it/s, loss=0.347, test_loss=0\n",
      "IAA - Fold 2:  72%|▋| 1442/2000 [00:51<00:20, 27.85it/s, loss=0.421, test_loss=0\n",
      "IAA - Fold 3:  42%|▍| 839/2000 [00:30<00:42, 27.41it/s, loss=0.454, test_loss=0.\n",
      "IAA - Fold 4:  67%|▋| 1338/2000 [00:48<00:23, 27.71it/s, loss=0.425, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9032\n",
      "Mean Sensitivity (IAA): 0.6308\n",
      "Mean Specificity (IAA): 0.9860\n",
      "Mean AUC (IAA): 0.9759\n",
      "Working on RA dataset: 322 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RA - Fold 0:  44%|▍| 873/2000 [00:35<00:45, 24.50it/s, loss=0.439, test_loss=0.5\n",
      "RA - Fold 1:  72%|▋| 1442/2000 [00:58<00:22, 24.63it/s, loss=0.429, test_loss=0.\n",
      "RA - Fold 2:  66%|▋| 1325/2000 [00:56<00:28, 23.41it/s, loss=0.467, test_loss=0.\n",
      "RA - Fold 3:  50%|▌| 1010/2000 [00:42<00:41, 23.90it/s, loss=0.416, test_loss=0.\n",
      "RA - Fold 4:  52%|▌| 1034/2000 [00:43<00:40, 23.99it/s, loss=0.447, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.8230\n",
      "Mean Sensitivity (RA): 0.5370\n",
      "Mean Specificity (RA): 0.9673\n",
      "Mean AUC (RA): 0.8900\n",
      "Working on T1D dataset: 411 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1D - Fold 0:  51%|▌| 1017/2000 [00:54<00:52, 18.68it/s, loss=0.407, test_loss=0\n",
      "T1D - Fold 1:  67%|▋| 1348/2000 [01:12<00:35, 18.58it/s, loss=0.468, test_loss=0\n",
      "T1D - Fold 2:  50%|▍| 997/2000 [00:54<00:54, 18.27it/s, loss=0.44, test_loss=0.0\n",
      "T1D - Fold 3:  56%|▌| 1130/2000 [01:00<00:46, 18.69it/s, loss=0.464, test_loss=0\n",
      "T1D - Fold 4:  67%|▋| 1349/2000 [01:11<00:34, 18.87it/s, loss=0.389, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9270\n",
      "Mean Sensitivity (T1D): 0.8782\n",
      "Mean Specificity (T1D): 0.9720\n",
      "Mean AUC (T1D): 0.9854\n",
      "Working on MS dataset: 508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS - Fold 0:  52%|▌| 1041/2000 [01:07<01:02, 15.37it/s, loss=0.464, test_loss=0.\n",
      "MS - Fold 1:  61%|▌| 1219/2000 [01:19<00:50, 15.32it/s, loss=0.427, test_loss=0.\n",
      "MS - Fold 2:  51%|▌| 1022/2000 [01:07<01:04, 15.20it/s, loss=0.478, test_loss=0.\n",
      "MS - Fold 3:  51%|▌| 1020/2000 [01:07<01:04, 15.11it/s, loss=0.412, test_loss=0.\n",
      "MS - Fold 4:  60%|▌| 1192/2000 [01:19<00:53, 15.05it/s, loss=0.464, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9685\n",
      "Mean Sensitivity (MS): 0.9728\n",
      "Mean Specificity (MS): 0.9626\n",
      "Mean AUC (MS): 0.9952\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IAA - Fold 0:  83%|▊| 1668/2000 [00:59<00:11, 27.89it/s, loss=0.436, test_loss=0\n",
      "IAA - Fold 1: 100%|█| 2000/2000 [01:11<00:00, 27.85it/s, loss=0.438, test_loss=0\n",
      "IAA - Fold 2:  65%|▋| 1302/2000 [00:45<00:24, 28.66it/s, loss=0.414, test_loss=0\n",
      "IAA - Fold 3:  80%|▊| 1591/2000 [00:56<00:14, 28.12it/s, loss=0.444, test_loss=0\n",
      "IAA - Fold 4:  58%|▌| 1164/2000 [00:41<00:30, 27.72it/s, loss=0.426, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9104\n",
      "Mean Sensitivity (IAA): 0.7231\n",
      "Mean Specificity (IAA): 0.9673\n",
      "Mean AUC (IAA): 0.9752\n",
      "Working on RA dataset: 322 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RA - Fold 0:  52%|▌| 1036/2000 [00:43<00:40, 23.99it/s, loss=0.416, test_loss=0.\n",
      "RA - Fold 1:  61%|▌| 1223/2000 [00:50<00:31, 24.39it/s, loss=0.421, test_loss=0.\n",
      "RA - Fold 2:  18%|▏| 350/2000 [00:14<01:07, 24.57it/s, loss=0.603, test_loss=0.6\n",
      "RA - Fold 3:  75%|▊| 1502/2000 [01:01<00:20, 24.37it/s, loss=0.429, test_loss=0.\n",
      "RA - Fold 4:  57%|▌| 1148/2000 [00:47<00:35, 24.17it/s, loss=0.381, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.7640\n",
      "Mean Sensitivity (RA): 0.3426\n",
      "Mean Specificity (RA): 0.9766\n",
      "Mean AUC (RA): 0.8243\n",
      "Working on T1D dataset: 411 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1D - Fold 0:  78%|▊| 1550/2000 [01:22<00:24, 18.68it/s, loss=0.41, test_loss=0.\n",
      "T1D - Fold 1:  66%|▋| 1317/2000 [01:11<00:37, 18.43it/s, loss=0.418, test_loss=0\n",
      "T1D - Fold 2:  53%|▌| 1061/2000 [00:57<00:50, 18.51it/s, loss=0.399, test_loss=0\n",
      "T1D - Fold 3:  55%|▌| 1100/2000 [00:59<00:48, 18.62it/s, loss=0.484, test_loss=0\n",
      "T1D - Fold 4:  58%|▌| 1167/2000 [01:02<00:44, 18.82it/s, loss=0.469, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9367\n",
      "Mean Sensitivity (T1D): 0.9086\n",
      "Mean Specificity (T1D): 0.9626\n",
      "Mean AUC (T1D): 0.9854\n",
      "Working on MS dataset: 508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS - Fold 0:  77%|▊| 1546/2000 [01:42<00:30, 15.11it/s, loss=0.451, test_loss=0.\n",
      "MS - Fold 1:  58%|▌| 1169/2000 [01:17<00:55, 15.09it/s, loss=0.378, test_loss=0.\n",
      "MS - Fold 2:  76%|▊| 1512/2000 [01:39<00:32, 15.14it/s, loss=0.442, test_loss=0.\n",
      "MS - Fold 3:  68%|▋| 1365/2000 [01:30<00:42, 15.06it/s, loss=0.412, test_loss=0.\n",
      "MS - Fold 4:  58%|▌| 1160/2000 [01:16<00:55, 15.13it/s, loss=0.447, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9488\n",
      "Mean Sensitivity (MS): 0.9422\n",
      "Mean Specificity (MS): 0.9579\n",
      "Mean AUC (MS): 0.9895\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IAA - Fold 0:  67%|▋| 1335/2000 [00:47<00:23, 28.19it/s, loss=0.419, test_loss=0\n",
      "IAA - Fold 1:  87%|▊| 1739/2000 [01:01<00:09, 28.42it/s, loss=0.456, test_loss=0\n",
      "IAA - Fold 2:  87%|▊| 1746/2000 [01:01<00:08, 28.44it/s, loss=0.428, test_loss=0\n",
      "IAA - Fold 3:  78%|▊| 1561/2000 [00:55<00:15, 28.00it/s, loss=0.411, test_loss=0\n",
      "IAA - Fold 4:  53%|▌| 1056/2000 [00:38<00:34, 27.66it/s, loss=0.366, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.8996\n",
      "Mean Sensitivity (IAA): 0.6154\n",
      "Mean Specificity (IAA): 0.9860\n",
      "Mean AUC (IAA): 0.9827\n",
      "Working on RA dataset: 322 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RA - Fold 0:  46%|▍| 913/2000 [00:38<00:46, 23.48it/s, loss=0.394, test_loss=0.4\n",
      "RA - Fold 1:  40%|▍| 791/2000 [00:32<00:49, 24.30it/s, loss=0.436, test_loss=0.7\n",
      "RA - Fold 2:  79%|▊| 1588/2000 [01:05<00:17, 24.12it/s, loss=0.434, test_loss=0.\n",
      "RA - Fold 3:  46%|▍| 916/2000 [00:37<00:44, 24.35it/s, loss=0.401, test_loss=0.4\n",
      "RA - Fold 4:  60%|▌| 1196/2000 [00:49<00:33, 24.20it/s, loss=0.388, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.7950\n",
      "Mean Sensitivity (RA): 0.5370\n",
      "Mean Specificity (RA): 0.9252\n",
      "Mean AUC (RA): 0.8532\n",
      "Working on T1D dataset: 411 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1D - Fold 0:  55%|▌| 1095/2000 [00:58<00:48, 18.60it/s, loss=0.395, test_loss=0\n",
      "T1D - Fold 1:  75%|▋| 1495/2000 [01:21<00:27, 18.34it/s, loss=0.484, test_loss=0\n",
      "T1D - Fold 2:  44%|▍| 872/2000 [00:47<01:01, 18.35it/s, loss=0.433, test_loss=0.\n",
      "T1D - Fold 3:  42%|▍| 849/2000 [00:45<01:01, 18.72it/s, loss=0.446, test_loss=0.\n",
      "T1D - Fold 4:  37%|▎| 740/2000 [00:39<01:08, 18.52it/s, loss=0.515, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9319\n",
      "Mean Sensitivity (T1D): 0.8832\n",
      "Mean Specificity (T1D): 0.9766\n",
      "Mean AUC (T1D): 0.9796\n",
      "Working on MS dataset: 508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS - Fold 0:  78%|▊| 1563/2000 [01:43<00:28, 15.11it/s, loss=0.49, test_loss=0.1\n",
      "MS - Fold 1:  68%|▋| 1356/2000 [01:28<00:41, 15.37it/s, loss=0.399, test_loss=0.\n",
      "MS - Fold 2:  62%|▌| 1247/2000 [01:21<00:49, 15.31it/s, loss=0.46, test_loss=0.1\n",
      "MS - Fold 3:  77%|▊| 1538/2000 [01:41<00:30, 15.19it/s, loss=0.423, test_loss=0.\n",
      "MS - Fold 4:  76%|▊| 1511/2000 [01:39<00:32, 15.24it/s, loss=0.389, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9705\n",
      "Mean Sensitivity (MS): 0.9592\n",
      "Mean Specificity (MS): 0.9860\n",
      "Mean AUC (MS): 0.9955\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IAA - Fold 0:  65%|▋| 1294/2000 [00:46<00:25, 27.87it/s, loss=0.429, test_loss=0\n",
      "IAA - Fold 1:  66%|▋| 1323/2000 [00:46<00:23, 28.27it/s, loss=0.389, test_loss=0\n",
      "IAA - Fold 2:  88%|▉| 1760/2000 [01:02<00:08, 28.22it/s, loss=0.39, test_loss=0.\n",
      "IAA - Fold 3: 100%|█| 2000/2000 [01:11<00:00, 28.14it/s, loss=0.411, test_loss=0\n",
      "IAA - Fold 4:  76%|▊| 1528/2000 [00:54<00:16, 28.27it/s, loss=0.427, test_loss=0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.8996\n",
      "Mean Sensitivity (IAA): 0.6769\n",
      "Mean Specificity (IAA): 0.9673\n",
      "Mean AUC (IAA): 0.9513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#参数设置\n",
    "def init_model():\n",
    "    input_size = 15\n",
    "    hidden_size =30\n",
    "    num_layers = 3\n",
    "    output_size = 1\n",
    "    ins_num = 100\n",
    "    dropout = 0.6\n",
    "    \n",
    "    return ModelLSTMAttention(input_size, hidden_size, output_size, num_layers, dropout, ins_num)\n",
    "\n",
    "# 引入早停机制\n",
    "sys.path.append('../')\n",
    "from python_codes.pytorchtools import EarlyStopping\n",
    "\n",
    "# 读取氨基酸特征文件\n",
    "aa_file = \"../Data/PCA15.txt\"\n",
    "aa_vectors = get_features(aa_file)  # 请确保 get_features 函数正确读取文件\n",
    "\n",
    "# 5折交叉验证\n",
    "k_fold = 5\n",
    "kf = KFold(n_splits=k_fold, shuffle=True,random_state=42)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHES = 2000\n",
    "PATIENCE = 300\n",
    "\n",
    "all_accuracies = []  # 存储每一折的准确率\n",
    "all_sensitivities = []  # 存储每一折的灵敏度\n",
    "all_specificities = []  # 存储每一折的特异度\n",
    "all_aucs = []  # 存储每一折的AUC值\n",
    "\n",
    "device = \"cuda\"\n",
    "disease_list = [\"RA\", \"T1D\", \"MS\", \"IAA\"]\n",
    "\n",
    "for _ in range(10):  # 循环20次\n",
    "    results = []\n",
    "    results_ROC = []\n",
    "\n",
    "    for disease_name in disease_list:\n",
    "        data_dir = f'../Data/{disease_name}'\n",
    "        training_data, training_labels = load_data(data_dir)\n",
    "        print(f\"Working on {disease_name} dataset: {len(training_data)} samples\")\n",
    "\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "\n",
    "        # 分成5折\n",
    "        for fold, (train_idx, test_idx) in enumerate(kf.split(training_data)):\n",
    "            train_data = [training_data[i] for i in train_idx]\n",
    "            train_labels = [training_labels[i] for i in train_idx]\n",
    "            test_data = [training_data[i] for i in test_idx]\n",
    "            test_labels = [training_labels[i] for i in test_idx]\n",
    "\n",
    "\n",
    "            # 训练集和测试集固定后，再将训练集划分为训练集和验证集\n",
    "            train_data, valid_data, train_labels, valid_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=1234)\n",
    "\n",
    "\n",
    "            train_input_batch, train_label_batch, train_valid_lens_batch = generate_input(train_data, train_labels, aa_vectors, 15, 100, 24)\n",
    "            valid_input_batch, valid_label_batch, valid_valid_lens_batch = generate_input(valid_data, valid_labels, aa_vectors, 15, 100, 24)\n",
    "            test_input_batch, test_label_batch, test_valid_lens_batch = generate_input(test_data, test_labels, aa_vectors, 15, 100, 24)\n",
    "\n",
    "            train_dataset = Data.TensorDataset(train_input_batch, train_label_batch, train_valid_lens_batch)\n",
    "            valid_dataset = Data.TensorDataset(valid_input_batch, valid_label_batch, valid_valid_lens_batch)\n",
    "            test_dataset = Data.TensorDataset(test_input_batch, test_label_batch, test_valid_lens_batch)\n",
    "\n",
    "            train_loader = Data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "            valid_loader = Data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "            test_loader = Data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "            model = init_model().to(device)\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "            train(fold, model, criterion, optimizer, train_loader, valid_loader, epoches=NUM_EPOCHES, device=device)\n",
    "\n",
    "            # 在测试集上进行最终评估\n",
    "            _, preds, labels = evaluate(model, criterion, test_loader, device=device)\n",
    "            all_preds += preds\n",
    "            all_labels += labels\n",
    "\n",
    "        all_preds = np.concatenate(all_preds, axis=0)\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        accuracy, sensitivity, specificity, auc = metrics(all_preds, all_labels)\n",
    "        print(f\"Mean Accuracy ({disease_name}): {accuracy:.4f}\")\n",
    "        print(f\"Mean Sensitivity ({disease_name}): {sensitivity:.4f}\")\n",
    "        print(f\"Mean Specificity ({disease_name}): {specificity:.4f}\")\n",
    "        print(f\"Mean AUC ({disease_name}): {auc:.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            'disease': disease_name,\n",
    "            'accuracy': accuracy,\n",
    "            'sensitivity': sensitivity,\n",
    "            'specificity': specificity,\n",
    "            'auc': auc\n",
    "        })\n",
    "\n",
    "        results_ROC.append({\n",
    "            'disease': disease_name,\n",
    "            'auc': auc,\n",
    "            'all_preds': all_preds,\n",
    "            'all_labels': all_labels\n",
    "        })\n",
    "        \n",
    "    # 将本次循环的性能指标值添加到列表中\n",
    "    all_accuracies.append([result['accuracy'] for result in results])\n",
    "    all_sensitivities.append([result['sensitivity'] for result in results])\n",
    "    all_specificities.append([result['specificity'] for result in results])\n",
    "    all_aucs.append([result['auc'] for result in results])\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7068e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.7888, Variance: 0.0004\n",
      "Mean Sensitivity (RA): 0.4639, Variance: 0.0049\n",
      "Mean Specificity (RA): 0.9528, Variance: 0.0003\n",
      "Mean AUC (RA): 0.8677, Variance: 0.0006\n",
      "Mean Accuracy (T1D): 0.9290, Variance: 0.0001\n",
      "Mean Sensitivity (T1D): 0.8807, Variance: 0.0004\n",
      "Mean Specificity (T1D): 0.9734, Variance: 0.0001\n",
      "Mean AUC (T1D): 0.9830, Variance: 0.0000\n",
      "Mean Accuracy (MS): 0.9695, Variance: 0.0001\n",
      "Mean Sensitivity (MS): 0.9622, Variance: 0.0001\n",
      "Mean Specificity (MS): 0.9794, Variance: 0.0002\n",
      "Mean AUC (MS): 0.9930, Variance: 0.0000\n",
      "Mean Accuracy (IAA): 0.9115, Variance: 0.0001\n",
      "Mean Sensitivity (IAA): 0.6769, Variance: 0.0027\n",
      "Mean Specificity (IAA): 0.9827, Variance: 0.0001\n",
      "Mean AUC (IAA): 0.9595, Variance: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# 计算性能指标的均值和方差\n",
    "mean_accuracy = np.mean(all_accuracies, axis=0)\n",
    "mean_sensitivity = np.mean(all_sensitivities, axis=0)\n",
    "mean_specificity = np.mean(all_specificities, axis=0)\n",
    "mean_auc = np.mean(all_aucs, axis=0)\n",
    "\n",
    "variance_accuracy = np.var(all_accuracies, axis=0)\n",
    "variance_sensitivity = np.var(all_sensitivities, axis=0)\n",
    "variance_specificity = np.var(all_specificities, axis=0)\n",
    "variance_auc = np.var(all_aucs, axis=0)\n",
    "\n",
    "# 打印均值和方差\n",
    "for idx, disease_name in enumerate(disease_list):\n",
    "    print(f\"Mean Accuracy ({disease_name}): {mean_accuracy[idx]:.4f}, Variance: {variance_accuracy[idx]:.4f}\")\n",
    "    print(f\"Mean Sensitivity ({disease_name}): {mean_sensitivity[idx]:.4f}, Variance: {variance_sensitivity[idx]:.4f}\")\n",
    "    print(f\"Mean Specificity ({disease_name}): {mean_specificity[idx]:.4f}, Variance: {variance_specificity[idx]:.4f}\")\n",
    "    print(f\"Mean AUC ({disease_name}): {mean_auc[idx]:.4f}, Variance: {variance_auc[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a42b4e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.7888, Statistics: 0.0202\n",
      "Mean Sensitivity (RA): 0.4639, Statistics: 0.0697\n",
      "Mean Specificity (RA): 0.9528, Statistics: 0.0170\n",
      "Mean AUC (RA): 0.8677, Statistics: 0.0245\n",
      "Mean Accuracy (T1D): 0.9290, Statistics: 0.0101\n",
      "Mean Sensitivity (T1D): 0.8807, Statistics: 0.0193\n",
      "Mean Specificity (T1D): 0.9734, Statistics: 0.0086\n",
      "Mean AUC (T1D): 0.9830, Statistics: 0.0042\n",
      "Mean Accuracy (MS): 0.9695, Statistics: 0.0097\n",
      "Mean Sensitivity (MS): 0.9622, Statistics: 0.0094\n",
      "Mean Specificity (MS): 0.9794, Statistics: 0.0148\n",
      "Mean AUC (MS): 0.9930, Statistics: 0.0029\n",
      "Mean Accuracy (IAA): 0.9115, Statistics: 0.0117\n",
      "Mean Sensitivity (IAA): 0.6769, Statistics: 0.0515\n",
      "Mean Specificity (IAA): 0.9827, Statistics: 0.0081\n",
      "Mean AUC (IAA): 0.9595, Statistics: 0.0181\n"
     ]
    }
   ],
   "source": [
    "# 计算性能指标的均值和标准差\n",
    "mean_accuracy = np.mean(all_accuracies, axis=0)\n",
    "mean_sensitivity = np.mean(all_sensitivities, axis=0)\n",
    "mean_specificity = np.mean(all_specificities, axis=0)\n",
    "mean_auc = np.mean(all_aucs, axis=0)\n",
    "\n",
    "Statistics_accuracy = np.std(all_accuracies, axis=0)\n",
    "Statistics_sensitivity = np.std(all_sensitivities, axis=0)\n",
    "Statistics_specificity = np.std(all_specificities, axis=0)\n",
    "Statistics_auc = np.std(all_aucs, axis=0)\n",
    "\n",
    "# 打印均值和标准差\n",
    "for idx, disease_name in enumerate(disease_list):\n",
    "    print(f\"Mean Accuracy ({disease_name}): {mean_accuracy[idx]:.4f}, Statistics: {Statistics_accuracy[idx]:.4f}\")\n",
    "    print(f\"Mean Sensitivity ({disease_name}): {mean_sensitivity[idx]:.4f}, Statistics: {Statistics_sensitivity[idx]:.4f}\")\n",
    "    print(f\"Mean Specificity ({disease_name}): {mean_specificity[idx]:.4f}, Statistics: {Statistics_specificity[idx]:.4f}\")\n",
    "    print(f\"Mean AUC ({disease_name}): {mean_auc[idx]:.4f}, Statistics: {Statistics_auc[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a80fb10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.7888, Statistics: 0.0202\n",
      "Mean Sensitivity (RA): 0.4639, Statistics: 0.0697\n",
      "Mean Specificity (RA): 0.9528, Statistics: 0.0170\n",
      "Mean AUC (RA): 0.8677, Statistics: 0.0245\n",
      "Mean Accuracy (T1D): 0.9290, Statistics: 0.0101\n",
      "Mean Sensitivity (T1D): 0.8807, Statistics: 0.0193\n",
      "Mean Specificity (T1D): 0.9734, Statistics: 0.0086\n",
      "Mean AUC (T1D): 0.9830, Statistics: 0.0042\n",
      "Mean Accuracy (MS): 0.9695, Statistics: 0.0097\n",
      "Mean Sensitivity (MS): 0.9622, Statistics: 0.0094\n",
      "Mean Specificity (MS): 0.9794, Statistics: 0.0148\n",
      "Mean AUC (MS): 0.9930, Statistics: 0.0029\n",
      "Mean Accuracy (IAA): 0.9115, Statistics: 0.0117\n",
      "Mean Sensitivity (IAA): 0.6769, Statistics: 0.0515\n",
      "Mean Specificity (IAA): 0.9827, Statistics: 0.0081\n",
      "Mean AUC (IAA): 0.9595, Statistics: 0.0181\n"
     ]
    }
   ],
   "source": [
    "# 计算性能指标的均值和标准差\n",
    "mean_accuracy = np.mean(all_accuracies, axis=0)\n",
    "mean_sensitivity = np.mean(all_sensitivities, axis=0)\n",
    "mean_specificity = np.mean(all_specificities, axis=0)\n",
    "mean_auc = np.mean(all_aucs, axis=0)\n",
    "\n",
    "Statistics_accuracy =np.sqrt(np.var(all_accuracies, axis=0)) \n",
    "Statistics_sensitivity = np.sqrt(np.var(all_sensitivities, axis=0))\n",
    "Statistics_specificity = np.sqrt(np.var(all_specificities, axis=0))\n",
    "Statistics_auc = np.sqrt(np.var(all_aucs, axis=0))\n",
    "\n",
    "# 打印均值和标准差\n",
    "for idx, disease_name in enumerate(disease_list):\n",
    "    print(f\"Mean Accuracy ({disease_name}): {mean_accuracy[idx]:.4f}, Statistics: {Statistics_accuracy[idx]:.4f}\")\n",
    "    print(f\"Mean Sensitivity ({disease_name}): {mean_sensitivity[idx]:.4f}, Statistics: {Statistics_sensitivity[idx]:.4f}\")\n",
    "    print(f\"Mean Specificity ({disease_name}): {mean_specificity[idx]:.4f}, Statistics: {Statistics_specificity[idx]:.4f}\")\n",
    "    print(f\"Mean AUC ({disease_name}): {mean_auc[idx]:.4f}, Statistics: {Statistics_auc[idx]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
