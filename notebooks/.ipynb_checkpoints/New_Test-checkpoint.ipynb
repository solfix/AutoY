{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "565b420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sparsemax import Sparsemax\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, auc, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Define dot product similarity\n",
    "class DotProductScore(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(DotProductScore, self).__init__()\n",
    "        self.q = nn.Parameter(torch.empty(size=(hidden_size, 1), dtype=torch.float32))\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.q.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Input：\n",
    "            - X：Input matrix，inputs=[batch_size,seq_length,hidden_size]\n",
    "        Output：\n",
    "            - scores：Output matrix，shape=[batch_size, seq_length]\n",
    "        \"\"\"\n",
    "        scores = torch.matmul(inputs, self.q)\n",
    "\n",
    "        scores = scores.squeeze(-1)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "# Define attention mechanisms\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.scores = DotProductScore(hidden_size)\n",
    "\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        scores = self.scores(X)\n",
    "        arrange = torch.arange(X.size(1), dtype=torch.float32, device=X.device).unsqueeze(0)\n",
    "        mask = (arrange < valid_lens.unsqueeze(-1)).float()\n",
    "        scores = scores * mask - (1 - mask) * 1e9\n",
    "        attention_weights = nn.functional.softmax(scores, dim=-1) \n",
    "        out = torch.matmul(attention_weights.unsqueeze(1), X).squeeze(1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "#Define the model class\n",
    "class ModelLSTMAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout, ins_num):\n",
    "        super(ModelLSTMAttention, self).__init__()\n",
    "        self.ins_num = ins_num\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout, bidirectional=True)       \n",
    "        self.attention = Attention(hidden_size * 2)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size * 2) \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc_1 = nn.Linear(self.ins_num, 1)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, seq, valid_lens):\n",
    "        \n",
    "        output, _ = self.lstm(seq)\n",
    "        valid_lens = valid_lens.view(-1,).to(device)\n",
    "        out = self.attention(output, valid_lens)\n",
    "        out = self.bn1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out.reshape(-1, self.ins_num)\n",
    "        out = self.fc_1(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# # Define functions to read TSV files\n",
    "def read_tsv(filename, inf_ind, skip_1st=False, file_encoding=\"utf8\"):\n",
    "    extract_inf = []\n",
    "    with open(filename, \"r\", encoding=file_encoding) as tsv_f:\n",
    "        if skip_1st:\n",
    "            tsv_f.readline()\n",
    "        line = tsv_f.readline()\n",
    "        while line:\n",
    "            line_list = line.strip().split(\"\\t\")\n",
    "            temp_inf = [line_list[ind] for ind in inf_ind]\n",
    "            extract_inf.append(temp_inf)\n",
    "            line = tsv_f.readline()\n",
    "    return extract_inf\n",
    "\n",
    "# Define a function that reads an amino acid feature file and generates a feature dictionary\n",
    "def get_features(filename, f_num=15):\n",
    "    f_list = read_tsv(filename, list(range(16)), True)\n",
    "    f_dict = {}\n",
    "    left_num = 0\n",
    "    right_num = 0\n",
    "    if f_num > 15:\n",
    "        left_num = (f_num - 15) // 2\n",
    "        right_num = f_num - 15 - left_num\n",
    "    for f in f_list:\n",
    "        f_dict[f[0]] = [0] * left_num + [float(x) for x in f[1:]] + [0] * right_num\n",
    "    f_dict[\"X\"] = [0] * f_num\n",
    "    return f_dict\n",
    "\n",
    "# Defining Input Functions\n",
    "def generate_input(sps, sp_lbs, feature_dict, feature_num, ins_num, max_len):\n",
    "    \n",
    "    xs, ys, lens = [], [], []\n",
    "    for i, sp in enumerate(sps):\n",
    "        ys.append(sp_lbs[i])\n",
    "        lens.extend([len(tcr[0]) if tcr[0] else 0 for tcr in sp])\n",
    "        \n",
    "    while len(lens) % ins_num != 0:\n",
    "        lens = np.concatenate((lens, np.array([0])))  \n",
    "    lens = np.array(lens)\n",
    "    lens = lens.reshape(-1, ins_num)\n",
    "    \n",
    "    while lens.shape[0] < len(sps):\n",
    "        lens = np.concatenate((lens, np.zeros((1, ins_num))), axis=0)\n",
    "        \n",
    "    for i, sp in enumerate(sps):\n",
    "        x = [[[0] * feature_num for _ in range(max_len)] for _ in range(ins_num)]\n",
    "        seq_count = 0  \n",
    "        for j, tcr in enumerate(sp):\n",
    "            tcr_seq = tcr[0]\n",
    "            right_num = max_len - len(tcr_seq)\n",
    "            tcr_seq += \"X\" * right_num\n",
    "            tcr_matrix = []\n",
    "            for aa in tcr_seq:\n",
    "                tcr_matrix.append(feature_dict[aa.upper()])\n",
    "            x[seq_count] = tcr_matrix\n",
    "            seq_count += 1\n",
    "\n",
    "        xs.append(x)\n",
    "\n",
    "    xs = np.array(xs)\n",
    "    xs = torch.tensor(xs, dtype=torch.float32)\n",
    "    xs = xs.swapaxes(2, 3)\n",
    "    ys = np.array(ys)\n",
    "    ys = torch.tensor(ys, dtype=torch.float32).view(-1, 1)\n",
    "    lens = torch.tensor(lens, dtype=torch.long)\n",
    "    \n",
    "    return xs, ys, lens\n",
    "\n",
    "#Define the Generate Label function\n",
    "def load_data(sample_dir):\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    for sample_file in os.listdir(sample_dir):\n",
    "        training_data.append(read_tsv(os.path.join(sample_dir, sample_file), [0, 1], True))\n",
    "        if \"P\" in sample_file:\n",
    "            training_labels.append(1)\n",
    "        elif \"H\" in sample_file:\n",
    "            training_labels.append(0)\n",
    "        else:\n",
    "            print(\"Wrong sample filename! Please name positive samples with 'P' and negative samples with 'H'.\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "    return training_data, training_labels\n",
    "\n",
    "#Define the evaluation function\n",
    "from tqdm import tqdm\n",
    "def evaluate(model, criterion, test_loader, device='cuda'):\n",
    "    test_total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_batch_x, test_batch_y, test_valid_lens in test_loader:\n",
    "            test_batch_x = test_batch_x.view(-1, 24, 15).to(device)\n",
    "            test_batch_y = test_batch_y.to(device)\n",
    "            test_pred = model(test_batch_x, test_valid_lens)\n",
    "\n",
    "            test_loss = criterion(test_pred, test_batch_y)\n",
    "            test_total_loss += test_loss.item()\n",
    "            all_preds.append(test_pred.cpu().numpy())\n",
    "            all_labels.append(test_batch_y.cpu().numpy())\n",
    "            \n",
    "        test_avg_loss = test_total_loss / len(test_loader)\n",
    "        return test_avg_loss, all_preds, all_labels\n",
    "    \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def metrics(all_preds, all_labels, threshold=0.5):\n",
    "    # 将 logits 转换为概率\n",
    "    all_probs = sigmoid(np.array(all_preds))\n",
    "    # 生成二进制预测结果\n",
    "    binary_preds = (all_probs > threshold).astype(int)\n",
    "    conf_matrix = confusion_matrix(all_labels, binary_preds)\n",
    "    accuracy = accuracy_score(all_labels, binary_preds)\n",
    "    sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    \n",
    "    return accuracy, sensitivity, specificity, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f7611dfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "LSTMY-New MS Samples - Accuracy: 0.8203, Sensitivity: 0.1786, Specificity: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Model parameterization\n",
    "def init_model():\n",
    "    input_size = 15\n",
    "    hidden_size =30\n",
    "    num_layers = 3\n",
    "    output_size = 1\n",
    "    ins_num = 100\n",
    "    dropout = 0.6\n",
    "    \n",
    "    return ModelLSTMAttention(input_size, hidden_size, output_size, num_layers, dropout, ins_num)\n",
    "\n",
    "# Introduce an early stop mechanism\n",
    "sys.path.append('../')\n",
    "from python_codes.pytorchtools import EarlyStopping\n",
    "\n",
    "# Reading amino acid profile files\n",
    "aa_file = \"../Data1/PCA15.txt\"\n",
    "aa_vectors = get_features(aa_file) \n",
    "\n",
    "device=\"cuda\"\n",
    "\n",
    "model_path = '../model/MScheckpoint.pt'\n",
    "\n",
    "# 加载训练好的模型\n",
    "model = init_model().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# 处理新的MS样本\n",
    "new_data_dir = '../New-MS/'  # 新样本的文件夹路径\n",
    "new_data, new_labels = load_data(new_data_dir)  # 假设新样本也有标签\n",
    "\n",
    "\n",
    "# 将新样本转换为模型可接受的格式\n",
    "new_input_batch, new_label_batch, new_valid_lens = generate_input(new_data, new_labels, aa_vectors, 15, 100, 24)\n",
    "\n",
    "# 将数据移动到指定设备上\n",
    "new_input_batch = new_input_batch.to(device)\n",
    "new_label_batch = new_label_batch.to(device)\n",
    "new_valid_lens = new_valid_lens.to(device)\n",
    "\n",
    "# 创建数据加载器\n",
    "new_dataset = Data.TensorDataset(new_input_batch, new_label_batch, new_valid_lens)\n",
    "new_loader = Data.DataLoader(new_dataset, batch_size=len(new_input_batch), shuffle=False)\n",
    "\n",
    "# 使用模型进行预测\n",
    "_, new_preds, new_labels = evaluate(model, criterion, new_loader, device=device)\n",
    "new_preds = np.concatenate(new_preds, axis=0)\n",
    "new_labels = np.concatenate(new_labels, axis=0)\n",
    "all_probs = sigmoid(np.array(new_preds))\n",
    "print(len(new_labels))\n",
    "# 计算评估指标\n",
    "accuracy, sensitivity, specificity, auc = metrics(new_preds, new_labels)\n",
    "print(f\"LSTMY-New MS Samples - Accuracy: {accuracy:.4f}, Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef6ab33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
